{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft\n",
    "from sklearn.model_selection import train_test_split\n",
    "from python_speech_features import mfcc\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import kurtosis, skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data.\n",
    "rootLocation = \"data/genres\" # directory which contains the folder of genres. \n",
    "genres = os.listdir(rootLocation)\n",
    "genres.remove('.DS_Store') if '.DS_Store' in genres else None\n",
    "data = list() # read .au files from librosa library\n",
    "labels = list() # list of labels\n",
    "\n",
    "for genre in genres:\n",
    "    clips = os.listdir(rootLocation+\"/{}\".format(genre))\n",
    "    clips.remove('.DS_Store') if '.DS_Store' in clips else None\n",
    "    \n",
    "    for clip in clips: # using first 2 songs from each genre. remove [:2] to loop through all songs.\n",
    "        musicLabel = clip.split('.',1)[0]\n",
    "        musicData = librosa.load('data/genres/{}/{}'.format(genre,clip))\n",
    "        #musicData = rootLocation + \"/{}/{}\".format(genre,clip)\n",
    "        \n",
    "        labels.append(musicLabel)\n",
    "        data.append(musicData)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Validation data:\n",
    "v_Location = \"data/validation\" # directory which contains the folder of genres. \n",
    "v_clips = os.listdir(v_Location)\n",
    "v_clips.array('.DS_Store') if '.DS_Store' in v_clips else None\n",
    "v_data = list() # read .au files from librosa library  \n",
    "v_label = list()\n",
    "for v_clip in v_clips:\n",
    "    v_musicData = librosa.core.load(v_Location+'/{}'.format(v_clip))\n",
    "    #musicData = rootLocation+\"/{}/{}\".format(genre,clip)\n",
    "    v_label.append(v_clip)\n",
    "    v_data.append(v_musicData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot spectrogram from the data read\n",
    "c = np.abs(librosa.stft(data[40][0]))\n",
    "librosa.display.specshow(librosa.power_to_db(c**2, ref=np.max),sr=data[2][1], y_axis='log', x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play the selected audio\n",
    "Audio(data = v_data[71][0], rate = v_data[71][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Feature ex\n",
    "# fast Fourier Transform feature extraction\n",
    "def fourierfeatures(data, n = 1000): # data in format [[y], sample_rate]\n",
    "    fft_features= []\n",
    "    for clip in data:\n",
    "        features = abs(fft(clip[0]))[:n]\n",
    "        m = max(features)\n",
    "        norm_features = [x / m for x in features]\n",
    "        fft_features.append(norm_features) # normalize the numbers between 0 and 1.\n",
    "    return fft_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCC feature extraction\n",
    "def mfccfeatures(data): # data in format [[y], sample_rate]\n",
    "    mfcc_features= []\n",
    "    for clip in data:\n",
    "        features= mfcc(clip[0])\n",
    "        avg_f = np.mean(features, axis=0)\n",
    "        m = max(avg_f)\n",
    "        norm_features = [x / m for x in avg_f]\n",
    "        mfcc_features.append(norm_features) \n",
    "    return mfcc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Feature extraction + MFCC feature extraction\n",
    "def customfeatures(data): # data in format [[y], sample_rate]\n",
    "    mfcc_features= []\n",
    "    for clip in data:\n",
    "        ## mfcc features as the base. \n",
    "        features= mfcc(clip[0],samplerate = clip[1], nftt = 600)\n",
    "        avg_f = np.mean(features, axis=0)\n",
    "        \n",
    "        ## add tempo value as the 14th feature\n",
    "        tempo = [a/15 for a in librosa.beat.tempo(y=clip[0], sr=clip[1])]\n",
    "        avg_f= np.append(avg_f, tempo)  # add tempo as 14th featur\n",
    "        \n",
    "        ## normalize between 0 and 1\n",
    "        #m = max(abs(avg_f))\n",
    "        #norm_features = [x/m for x in avg_f]\n",
    "        mfcc_features.append(avg_f) \n",
    "    return mfcc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBest_Features(data):\n",
    "    i = 0\n",
    "    best_features= list()\n",
    "    for clip in data:\n",
    "        features= mfcc(clip[0])\n",
    "        avg_f = np.mean(features, axis=0)\n",
    "        std_f = np.std(features,axis=0)\n",
    "        skew_f = skew (features, axis =0)\n",
    "        kurt_f = kurtosis(features, axis =0)\n",
    "        addList = np.concatenate((avg_f,std_f,skew_f,kurt_f))\n",
    "        best_features.append(addList)\n",
    "        i +=1\n",
    "        print(i)\n",
    "    return best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhythm= librosa.feature.tempogram(data[0][0], sr = data[0][1])\n",
    "avg_f = np.mean(rhythm, axis=0)\n",
    "\n",
    "#print(pd.DataFrame(avg_f))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = getBest_Features(data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validating_features = getBest_Features(data = v_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(training_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COnvert to Pandas dataframe.. better compatibility with the algorithms\n",
    "tdf = pd.DataFrame(training_features)\n",
    "vdf = pd.DataFrame(validating_features)\n",
    "ldf = pd.DataFrame(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encapsulate other ML libraries\n",
    "def genericML1(trainingdata,traininglabels):\n",
    "    model = RandomForestClassifier(n_estimators= 800) # constructor for ML class\n",
    "    model.fit(trainingdata, traininglabels)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encapsulate other ML libraries\n",
    "def genericML2(trainingdata,traininglabels):\n",
    "    model = MLPClassifier(max_iter = 1000, random_state =2) # constructor for Ml class\n",
    "    model.fit(trainingdata,traininglabels)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tdf, ldf, test_size=0.2, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlObj = genericML1(tdf,ldf.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = mlObj.predict(vdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "prediction = mlObj.predict(vdf)\n",
    "#actual = list(y_test.values)\n",
    "#print(list(actual.values))\n",
    "count=0\n",
    "for p,a in zip(prediction,actual):\n",
    "    if p == a: count += 1 \n",
    "print(count/len(prediction))\n",
    "#print(y_test)\n",
    "    \n",
    "#print(v_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv file\n",
    "with open('predict.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile,lineterminator='\\n')\n",
    "    writer.writerow(['id', 'class'])\n",
    "    for file , p_label in zip(v_label, prediction):\n",
    "        writer.writerow([str(file),str(p_label)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
